```html
<html><body>
<div class="image" data-bbox="132 94 501 326"><img data-bbox="132 94 501 326"/></div> 
 <p data-bbox="83 332 537 373">Fig. 10: Qualitative comparison of performance metrics on the CIFAR-100 dataset.</p> 
 <p data-bbox="83 411 537 452">convergence can be attributed to AWCL’s ability to dynamically reweight sample pairs based on their informativeness.</p> 
 <h2 data-bbox="243 476 378 497">V. Conclusion</h2> 
 <p data-bbox="83 504 537 860">In this paper, we propose the Diffusion Contrastive Learning (DiffCL) framework to establish robust decision boundaries for image classification tasks. DiffCL consists of three key components: Cross-Centroid Asymmetric Reconstruction (CCAR) for semantically-aware hard sample initialization, Mutual Sample Inversion (MSI) for adaptive generation of boundary-refining samples, and Adaptive Weighted Contrastive Loss (AWCL) for information-sensitive representation optimization. The CCAR pipeline focuses on samples near class boundaries, compelling the model to learn finer-grained discriminative features for enhanced classification performance. The MSI mechanism adaptively generates synthetic samples that closely adhere to the real data distribution, thereby expanding the search space for decision boundary refinement. In addition, the AWCL addresses the imbalance and difficulty discrepancies among training samples, enabling DiffCL to focus more effectively on challenging scenarios. We rigorously evaluate the effectiveness and superiority of DiffCL across four benchmark datasets. Empirical results consistently demonstrate its robust classification performance.</p> 
 <h2 data-bbox="269 883 380 902">References</h2> 
 <p data-bbox="94 912 537 978">[1] Shekoofeh Azizi, Simon Kornblith, Chitwan Saharia, Mohammad Norouzi, and David J Fleet. Synthetic data from diffusion models improves imagenet classification. Transactions on Machine Learning Research, 2023.</p> 
 <p data-bbox="94 978 537 1033">[2] Carlo Alberto Barbano, Benoit Dufumier, Enzo Tartaglione, Marco Grangetto, and Pietro Gori. Unbiased supervised contrastive learning. In The Eleventh International Conference on Learning Representations, 2023.</p> 
 <p data-bbox="94 1039 537 1065">[3] Glenn W Brier. Verification of forecasts expressed in terms of probability. Monthly weather review, 78(1):1–3, 1950.</p> 
 <p data-bbox="94 1072 537 1108">[4] Jane Bromley, Isabelle Guyon, Yann LeCun, Eduard Säckinger, and Roopak Shah. Signature verification using a “siamese” time delay neural network. Advances in neural information processing systems, 6, 1993.</p> 
 <p data-bbox="94 1120 537 1156">[5] C. J. C. Burges. A tutorial on support vector machines for pattern recognition. Data Mining and Knowledge Discovery, 2(2):121–167, 1998.</p> 
 <p data-bbox="94 1169 537 1210">[6] T. Chen, S. Kornblith, M. Norouzi, and G. Hinton. A simple framework for contrastive learning of visual representations. In Proceedings of the 37th International Conference on Machine Learning (ICML), volume 119, pages 1597–1607, 2020.</p> 
 <p data-bbox="94 1210 537 1265">[7] Zihao Chen, Chi-Heng Lin, Ran Liu, Jingyun Xiao, and Eva Dyer. Your contrastive learning problem is secretly a distribution alignment problem. Advances in Neural Information Processing Systems, 37:91597–91617, 2025.</p> 
 <p data-bbox="94 1265 537 1320">[8] Ching-Yao Chuang, Joshua Robinson, Yen-Chen Lin, Antonio Torralba, and Stefanie Jegelka. Debiased contrastive learning. Advances in neural information processing systems, 33:8765–8775, 2020.</p> 
 <p data-bbox="589 98 1008 144"> [9] Yusuf Dalva and Pinar Yanardag. Noiseclr: A contrastive learning approach for unsupervised discovery of interpretable directions in diffusion models. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 24209–24218, 2024.</p> 
 <p data-bbox="589 141 1008 197">[10] Jesse Davis and Mark Goadrich. The relationship between precisionrecall and roc curves. In Proceedings of the 23rd international conference on Machine learning, pages 233–240, 2006.</p> 
 <p data-bbox="589 197 1008 252">[11] Aditya M Deshpande, Ali A Minai, and Manish Kumar. One-shot recognition of manufacturing defects in steel surfaces. Procedia Manufacturing, 48:1064–1071, 2020.</p> 
 <p data-bbox="589 259 1008 295">[12] Hengkui Dong, Xianzhong Long, and Yun Li. Synthetic hard negative samples for contrastive learning. Neural Processing Letters, 56(1):33, 2024.</p> 
 <p data-bbox="589 308 1008 354">[13] Alexander Gielisse and Jan van Gemert. End-to-end implicit neural representations for classification. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2025.</p> 
 <p data-bbox="589 359 1008 385">[14] H. Guo and B. Li. Critical role of steel plates in automotive and defense industries. Materials Science and Engineering, 59(4):205–218, 2021.</p> 
 <p data-bbox="589 392 1008 452">[15] K. He, H. Fan, Y. Wu, S. Xie, and R. Girshick. Momentum contrast for unsupervised visual representation learning. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 9729–9738, 2020.</p> 
 <p data-bbox="589 455 1008 501">[16] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 770–778, 2016.</p> 
 <p data-bbox="589 506 1008 552">[17] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 770–778, 2016.</p> 
 <p data-bbox="589 560 1008 615">[18] Ruifei He, Shuyang Sun, Xin Yu, Chuhui Xue, Wenqing Zhang, Philip Torr, Song Bai, and XIAOJUAN QI. Is synthetic data from generative models ready for image recognition? In The Eleventh International Conference on Learning Representations, 2023.</p> 
 <p data-bbox="589 620 1008 697">[19] Yu He, Kechen Song, Qinggang Meng, and Yunhui Yan. An end-to-end steel surface defect detection approach via fusing multiple hierarchical features. IEEE transactions on instrumentation and measurement, 69(4):1493–1504, 2019.</p> 
 <p data-bbox="589 700 1008 736">[20] Jerry L Hintze and Ray D Nelson. Violin plots: a box plot-density trace synergism. The American Statistician, 52(2):181–184, 1998.</p> 
 <p data-bbox="589 736 1008 791">[21] Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. Advances in neural information processing systems, 33:6840–6851, 2020.</p> 
 <p data-bbox="589 791 1008 858">[22] R. Hu and L. Wang. Challenges in achieving high-precision steel defect classification. Advances in Manufacturing Systems, 22(4):250–264, 2024.</p> 
 <p data-bbox="589 860 1008 906">[23] Tao Huang, Jiaqi Liu, Shan You, and Chang Xu. Active generation for image classification. In European Conference on Computer Vision, pages 270–286. Springer, 2024.</p> 
 <p data-bbox="589 909 1008 945">[24] Weibo Huang and Peng Wei. A pcb dataset for defects detection and classification. arXiv preprint arXiv:1901.08204, 2019.</p> 
 <p data-bbox="589 945 1008 978">[25] Lawrence Hubert and Phipps Arabie. Comparing partitions. Journal of classification, 2:193–218, 1985.</p> 
 <p data-bbox="589 981 1008 1033">[26] P. Khosla, P. Teterwak, C. Wang, A. Sarna, Y. Tian, P. Isola, A. Maschinot, D. Krishnan, J. Shlens, and S. Bengio. Supervised contrastive learning. In Advances in Neural Information Processing Systems (NeurIPS), pages 18661–18673, 2020.</p> 
 <p data-bbox="589 1036 1008 1062">[27] Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. 2009.</p> 
 <p data-bbox="589 1065 1008 1108">[28] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification with deep convolutional neural networks. Advances in neural information processing systems, 25, 2012.</p> 
 <p data-bbox="589 1111 1008 1156">[29] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. Convolutional networks for images, speech, and time series. In The Handbook of Brain Theory and Neural Networks, pages 255–258. MIT Press, Cambridge, MA, 1995.</p> 
 <p data-bbox="589 1159 1008 1204">[30] Xiangyong Lu, Masanori Suganuma, and Takayuki Okatani. Sbcformer: lightweight network capable of full-size imagenet classification at 1 fps on single board computers. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pages 1123–1133, 2024.</p> 
 <p data-bbox="589 1207 1008 1252">[31] Qiwu Luo, Xiaoxin Fang, Li Liu, Chunhua Yang, and Yichuang Sun. Automated visual defect detection for flat steel surface: A survey. IEEE Transactions on Instrumentation and Measurement, 69(3):626–644, 2020.</p> 
 <p data-bbox="589 1255 1008 1291">[32] Y. Matsuda, K. Suzuki, and M. Tanaka. Lighting condition adaptation for steel defect classification. [Journal Name], 2022.</p> 
 <p data-bbox="589 1294 1008 1350">[33] Mehdi Mirza and Simon Osindero. Conditional generative adversarial nets. arXiv preprint arXiv:1411.1784, 2014.</p> 
</body></html>
```