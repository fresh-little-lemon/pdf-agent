```html
<html><body>
<p data-bbox="83 102 546 181">marizes a few relevant studies. Section III formulates the proposed methodology. Section IV presents the results and comprehensively compares them against previous literature. Finally, Section V concludes this article.</p> 
 <h2 data-bbox="232 217 389 237">II. RELATED WORK</h2> 
 <h2 data-bbox="84 243 297 262">A. Steel Defect Classification</h2> 
 <p data-bbox="83 267 546 528">The accurate and automated classification of surface defects in steel is critical for ensuring product quality and safety [57]. In the context of steel rolling production lines, subsequent decision-making processes such as defect rejection, rolling parameter adjustment, or alarm-triggered shutdowns, typically rely solely on determining the presence of a defect within a specified region of interest (ROI) and identifying its category [11]. Precise localization at the pixel level is generally redundant, as such spatial information is not integrated into downstream operational workflows [31]. Consequently, detection tasks that incorporate both localization and classification tend to increase system complexity without offering corresponding gains in practical utility. A streamlined approach that focuses exclusively on defect classification is therefore of considerable applied significance.</p> 
 <p data-bbox="83 526 546 924">Early research [5] on defect classification predominantly relied on hand-crafted features to identify anomalies based on descriptors like texture, shape, or color histograms. Although these classical approaches performed well for relatively simple defect patterns, they struggled to generalize to the complex and highly variable characteristics inherent in industrial steel surface data. As a result, their scalability to large-scale applications was limited, mainly due to insufficient robustness against inter-class similarities and environmental variations. With the advent of deep learning, Neural Networks [16], [29] replaced traditional feature engineering by automatically learning relevant representations. Real-world steel defects are subject to environmental factors such as lighting, angle, and background clutter, which introduce considerable variability and complicate classification [32]. In response, novel paradigms [6], [21], [43] have been introduced to better handle complex defect manifolds. While these improvements have significantly advanced the effectiveness of steel defect classification, several challenges remain. Chief among them is distinguishing between defect types that exhibit high visual similarity, as well as ensuring robust performance under diverse production conditions [36].</p> 
 <h2 data-bbox="84 948 260 969">B. Contrastive Learning</h2> 
 <p data-bbox="83 974 546 1354">Contrastive learning (CL) has emerged as a leading self-supervised representation learning method, extracting discriminative features without relying on labeled data. SimCLR [6] maximizes the agreement between augmented views of the same image, utilizing large batch sizes to generate diverse negative samples. However, its computational demands present significant challenges. To address this constraint, MoCo [15] introduces a momentum encoder and a dynamic queue to store negative samples across iterations. Despite these advancements, both self-supervised CL methods still face the class conflict problem, where semantically similar samples from the same class are pushed apart due to the lack of label awareness. SupCon [26] mitigates this issue by incorporating label supervision to define sample relationships. However, SupCon remains dependent on data augmentation, which may limit diversity and informativeness, particularly near decision boundaries where random augmentations fail to capture subtle differences. Recent studies have explored generative approaches to address the shortcomings of augmentation-based sample construction. By introducing synthesized samples, generative methods [33], [37], [53] aim to expand the diversity of</p> 
 <p data-bbox="554 102 1008 163">the representation space. These strategies demonstrate that generative CL can mitigate the inherent limitations of traditional augmentations by introducing structurally diverse samples.</p> 
 <p data-bbox="554 161 1008 439">Building upon these advancements, DiffCL strategically directs sample generation toward regions near decision boundaries, where class ambiguity tends to be most pronounced. In contrast to prior approaches that primarily manipulate global styles or background attributes, DiffCL explicitly targets the marginal space between classes to synthesize hard samples that actively challenge the model during training. A key distinction between DiffCL and existing generative contrastive methods lies in its dynamic generation mechanism. Whereas previous methods often rely on pre-generated synthetic samples stored offline and reused throughout training, DiffCL produces hard samples in real time, conditioned on the modelâ€™s evolving representation space and decision surface. This on-the-fly generation ensures that sample difficulty remains adaptive to the current state of learning, thereby enabling more effective contrastive supervision.</p> 
 <h2 data-bbox="555 453 712 473">C. Diffusion Models</h2> 
 <p data-bbox="554 478 1008 779">Diffusion models [21] have recently emerged as a powerful approach in generative modeling, outperforming traditional methods such as generative adversarial networks (GANs) in both performance and training stability. Unlike GANs, which are prone to issues like mode collapse and training instability, diffusion models progressively add noise to the data and subsequently learn to reverse this process. This step-by-step denoising mechanism enables the generation of high-quality and stable outputs. Building on the foundation of denoising diffusion probabilistic models (DDPM), Song et al. introduced denoising diffusion implicit models (DDIM) [44]. DDIM enhances both the speed and quality of image generation by optimizing the sampling process and reducing the number of denoising steps required. This optimization decreases computational costs, making diffusion models more efficient and capable of handling more complex tasks without compromising output quality.</p> 
 <p data-bbox="554 774 1008 1095">DiffCL employs a diffusion backbone grounded in DDPM [21] with computational efficiency enhanced through DDIM [44] sampling. To address the computational demands inherent in contrastive learning paradigms, we devise a task-aware sampling adaptation mechanism that reduces the number of sampling steps to only 3, which in turn reduces inference time to $1.59\%$ of base DDPM implementations, thereby significantly accelerating the overall contrastive training process. Diverging from diffusion-based classifiers that rely on direct guidance, DiffCL achieves dual functionality: preserving latent space generative properties through integrated image synthesis while enabling discriminative classification via a multi-view contrastive objective. By coupling the generative flexibility of diffusion models with the discriminative strengths of deep neural architectures, DiffCL effectively addresses the issue of semantic insufficiency often observed in conventional classification training, particularly in ambiguous or fine-boundary regions.</p> 
 <h2 data-bbox="721 1105 837 1126">III. METHODS</h2> 
 <h2 data-bbox="555 1131 728 1151">A. Problem Formulation</h2> 
 <p data-bbox="554 1154 1008 1254">In industrial defect classification, we consider a dataset $\mathcal{D}=\left\{\left(\mathbf{x}_{i}, y_{i}\right)\right\}_{i=1}^{N}$ where each sample $\mathbf{x}_{i} \in \mathbb{R}^{d}$ represents surface defect characteristics and $y_{i} \in \mathcal{Y}=\{1,2, \ldots, K\}$ denotes $K$ defect categories. The classification objective learns a mapping $f: \mathbb{R}^{d} \rightarrow \mathcal{Y}$ satisfying:</p> 
 <div class="formula" data-bbox="674 1275 884 1306"><img data-bbox="674 1275 884 1306"/><div>$$f\left(\mathbf{x}_{i}\right)=y_{i} \quad \forall i \in\{1, \ldots, N\} .$$</div></div> 
 <p data-bbox="554 1309 1008 1329">If the posterior probabilities $P\left(y_{i} \mid \mathbf{x}\right)$ and $P\left(y_{j} \mid \mathbf{x}\right), y_{i} \neq y_{j}$ for the same input $\mathbf{x}$, become nearly indistinguishable:</p> 
 <div class="formula" data-bbox="708 1329 850 1357"><img data-bbox="708 1329 850 1357"/><div>$$P\left(y_{i} \mid \mathbf{x}\right) \approx P\left(y_{j} \mid \mathbf{x}\right),$$</div></div> 
</body></html>
```