```html
<html><body>
<p data-bbox="83 117 540 200">TABLE VIII: Quantitative comparison of the proposed DiffCL with other methods on the CIFAR-100 dataset, evaluated using performance metrics including confusion count, silhouette score, ARI, NMI, and IDR.</p> 
 <div class="table" data-bbox="126 206 494 479" style="text-align: center"><table><tbody><tr><td colspan="1" style="text-align: center">Method</td><td colspan="5" style="text-align: center">Confusion Count $\downarrow$ Silhouette Score $\uparrow \mathrm{ARI} \uparrow \mathrm{NMI} \uparrow \mathrm{IDR} \uparrow$</td></tr><tr><td colspan="1" style="text-align: left">Baseline</td><td class="_empty" style="text-align: center"></td><td class="_empty" style="text-align: center"></td><td class="_empty" style="text-align: center"></td><td class="_empty" style="text-align: center"></td><td class="_empty" style="text-align: center"></td></tr><tr><td style="text-align: left">Tip-Adapter [55]</td><td style="text-align: center">8674</td><td style="text-align: center">$-0.2396$</td><td style="text-align: center">0.1740</td><td style="text-align: center">0.4832</td><td style="text-align: center">2.4347</td></tr><tr><td style="text-align: left">EMO-1M [54]</td><td style="text-align: center">1971</td><td style="text-align: center">$-0.2031$</td><td style="text-align: center">0.0423</td><td style="text-align: center">0.1421</td><td style="text-align: center">0.6745</td></tr><tr><td style="text-align: left">EMO-6M [54]</td><td style="text-align: center">1799</td><td style="text-align: center">$-0.2240$</td><td style="text-align: center">0.0387</td><td style="text-align: center">0.1352</td><td style="text-align: center">0.6425</td></tr><tr><td style="text-align: left">CAS-VIT-M [56]</td><td style="text-align: center">1891</td><td style="text-align: center">$-0.2087$</td><td style="text-align: center">0.0419</td><td style="text-align: center">0.1307</td><td style="text-align: center">0.5674</td></tr><tr><td style="text-align: left">SBCFormer-B [30]</td><td style="text-align: center">1952</td><td style="text-align: center">$-0.1923$</td><td style="text-align: center">0.0384</td><td style="text-align: center">0.1252</td><td style="text-align: center">0.6167</td></tr><tr><td style="text-align: left">MWT [13]</td><td style="text-align: center">1898</td><td style="text-align: center">$-0.2010$</td><td style="text-align: center">0.0574</td><td style="text-align: center">0.1605</td><td style="text-align: center">0.6517</td></tr><tr><td colspan="1" style="text-align: left">Contrastive</td><td class="_empty" style="text-align: center"></td><td class="_empty" style="text-align: center"></td><td class="_empty" style="text-align: center"></td><td class="_empty" style="text-align: center"></td><td class="_empty" style="text-align: center"></td></tr><tr><td style="text-align: left">SimCLR [6]</td><td style="text-align: center">908</td><td style="text-align: center">0.2150</td><td style="text-align: center">0.5387</td><td style="text-align: center">0.6618</td><td style="text-align: center">3.7924</td></tr><tr><td style="text-align: left">SupCon [26]</td><td style="text-align: center">595</td><td style="text-align: center">0.3743</td><td style="text-align: center">0.7053</td><td style="text-align: center">0.7862</td><td style="text-align: center">5.4970</td></tr><tr><td style="text-align: left">HCL [38]</td><td style="text-align: center">1954</td><td style="text-align: center">$-0.1757$</td><td style="text-align: center">0.0216</td><td style="text-align: center">0.0890</td><td style="text-align: center">0.4203</td></tr><tr><td colspan="1" style="text-align: left">Robustness</td><td class="_empty" style="text-align: center"></td><td class="_empty" style="text-align: center"></td><td class="_empty" style="text-align: center"></td><td class="_empty" style="text-align: center"></td><td class="_empty" style="text-align: center"></td></tr><tr><td style="text-align: left">Decoupled [52]</td><td style="text-align: center">845</td><td style="text-align: center">0.2350</td><td style="text-align: center">0.5686</td><td style="text-align: center">0.6987</td><td style="text-align: center">4.0958</td></tr><tr><td style="text-align: left">ADNCE [50]</td><td style="text-align: center">1953</td><td style="text-align: center">$-0.1784$</td><td style="text-align: center">0.0268</td><td style="text-align: center">0.0990</td><td style="text-align: center">0.4092</td></tr><tr><td style="text-align: left">GCA [7]</td><td style="text-align: center">1929</td><td style="text-align: center">$-0.1805$</td><td style="text-align: center">0.0333</td><td style="text-align: center">0.1136</td><td style="text-align: center">0.5023</td></tr><tr><td colspan="1" style="text-align: left">Debiasing</td><td class="_empty" style="text-align: center"></td><td class="_empty" style="text-align: center"></td><td class="_empty" style="text-align: center"></td><td class="_empty" style="text-align: center"></td><td class="_empty" style="text-align: center"></td></tr><tr><td style="text-align: left">FairKL [2]</td><td style="text-align: center">1926</td><td style="text-align: center">$-0.1965$</td><td style="text-align: center">0.0423</td><td style="text-align: center">0.1343</td><td style="text-align: center">0.6471</td></tr><tr><td style="text-align: left">DCL [8]</td><td style="text-align: center">1947</td><td style="text-align: center">$-0.1641$</td><td style="text-align: center">0.0277</td><td style="text-align: center">0.1008</td><td style="text-align: center">0.3563</td></tr><tr><td style="text-align: left">DiffCL</td><td style="text-align: center">486</td><td style="text-align: center">0.4251</td><td style="text-align: center">0.7532</td><td style="text-align: center">0.8170</td><td style="text-align: center">5.9454</td></tr></tbody></table></div> 
 <div class="image" data-bbox="104 551 532 678"><img data-bbox="104 551 532 678"/></div> 
 <div class="image" data-bbox="83 704 532 832"><img data-bbox="83 704 532 832"/></div> 
 <p data-bbox="83 858 539 899">Fig. 7: Qualitative analysis of the calibration ability using a violin plot on the 20 superclasses of the CIFAR-100 dataset.</p> 
 <p data-bbox="83 959 540 1021">TABLE IX: Quantitative comparison of the calibration quality of the proposed DiffCL with other methods on the CIFAR-100 dataset, evaluated using the Brier Score and NLL.</p> 
 <div class="table" data-bbox="158 1025 458 1327" style="text-align: center"><table><tbody><tr><td colspan="1" style="text-align: center">Method</td><td colspan="1" style="text-align: center">Brier Score $\downarrow$</td><td colspan="1" style="text-align: center">NLL $\downarrow$</td></tr><tr><td colspan="3" style="text-align: center">Baseline</td></tr><tr><td style="text-align: left">Tip-Adapter [55]</td><td style="text-align: center">0.0059</td><td style="text-align: center">1.6596</td></tr><tr><td style="text-align: left">EMO-1M [54]</td><td style="text-align: center">0.0049</td><td style="text-align: center">1.3899</td></tr><tr><td style="text-align: left">EMO-6M [54]</td><td style="text-align: center">0.0046</td><td style="text-align: center">1.3452</td></tr><tr><td style="text-align: left">CAS-VIT-M [56]</td><td style="text-align: center">0.0036</td><td style="text-align: center">0.9798</td></tr><tr><td style="text-align: left">SBCFormer-B [30]</td><td style="text-align: center">0.0049</td><td style="text-align: center">1.4743</td></tr><tr><td style="text-align: left">MWT [13]</td><td style="text-align: center">0.0094</td><td style="text-align: center">4.2941</td></tr><tr><td colspan="3" style="text-align: center">Contrastive</td></tr><tr><td style="text-align: left">SimCLR [6]</td><td style="text-align: center">0.0040</td><td style="text-align: center">1.0558</td></tr><tr><td style="text-align: left">SupCon [26]</td><td style="text-align: center">0.0033</td><td style="text-align: center">0.9794</td></tr><tr><td style="text-align: left">HCL [38]</td><td style="text-align: center">0.0046</td><td style="text-align: center">1.2958</td></tr><tr><td colspan="3" style="text-align: center">Robustness</td></tr><tr><td style="text-align: left">Decoupled [52]</td><td style="text-align: center">0.0043</td><td style="text-align: center">1.1471</td></tr><tr><td style="text-align: left">ADNCE [50]</td><td style="text-align: center">0.0040</td><td style="text-align: center">1.0617</td></tr><tr><td style="text-align: left">GCA [7]</td><td style="text-align: center">0.0071</td><td style="text-align: center">2.2201</td></tr><tr><td colspan="3" style="text-align: center">Debiasing</td></tr><tr><td style="text-align: left">FairKL [2]</td><td style="text-align: center">0.0057</td><td style="text-align: center">5.7218</td></tr><tr><td style="text-align: left">DCL [8]</td><td style="text-align: center">0.0042</td><td style="text-align: center">1.1284</td></tr><tr><td style="text-align: left">DiffCL</td><td style="text-align: center">0.0031</td><td style="text-align: center">0.8385</td></tr></tbody></table></div> 
 <h2 data-bbox="556 101 932 141">E. The Generalization Analysis of DiffCL for Broader Applications</h2> 
 <ol data-bbox="556 143 768 165"><li data-bbox="556 143 768 165">Generalization Evaluation of PCB Dataset:</li></ol> 
 <p data-bbox="555 165 1012 561">To evaluate the generalization performance of DiffCL, we extend our analysis to the PKU-Market-PCB dataset. As shown in Table III, DiffCL achieves the highest performance across all key classification metrics, with an accuracy of $98.78 \%$, a macro F1 score of 0.9879 , and an AUROC of 0.9998 . These results demonstrate DiffCL’s remarkable ability to transfer learned representations to new domains, highlighting its versatility across different industrial datasets. In addition to classification metrics, we further assess the quality of DiffCL’s feature embeddings using t-SNE visualizations and unsupervised clustering metrics. As depicted in Figure 4 and summarized in Table IV, DiffCL excels in clustering, as evidenced by the lowest confusion count (145) and superior unsupervised clustering metrics. Specifically, DiffCL achieves the highest silhouette score of 0.7082 , ARI of 0.9681 , and NMI of 0.9565 , indicating a coherent feature space with strong inter-class separability. Moreover, DiffCL demonstrates significantly improved confidence estimation, as seen in Table V. It achieves the lowest Brier Score of 0.0031 and NLL of 0.0396 , highlighting its ability to provide well-calibrated predictions. The violin plots in Figure 5 further illustrate the sharper confidence distribution, reinforcing the model’s strong calibration performance.</p> 
 <ol data-bbox="555 561 1009 600" start="2"><li data-bbox="555 561 1009 600">Scalability to Natural Image Domains of CIFAR-100:</li></ol> 
 <p data-bbox="555 586 1012 938">We also assess DiffCL’s scalability to more complex natural image datasets, specifically CIFAR-100. As reported in Table VI, DiffCL achieves $78.31 \%$ top-1 accuracy and a macro F1 score of 0.7841 , outperforming all baseline contrastive, robust, and generative models. This result confirms DiffCL’s ability to generalize across diverse datasets, extending its strengths beyond industrial defect detection to natural image domains. Feature embedding quality metrics, as shown in Table VIII, further support the effectiveness of DiffCL. It achieves the highest ARI of 0.7532 and NMI of 0.8170 , while reducing the confusion count to 486 . These improvements underscore DiffCL’s capacity to learn well-separated class manifolds. Notably, DiffCL achieves a silhouette score of 0.4251 and an IDR of 5.95 , surpassing all other methods, as illustrated in Figure 6. In terms of confidence estimation, DiffCL again demonstrates strong calibration performance, with a low Brier Score and NLL (Table IX). The sharp and reliable confidence distribution, visualized in the violin plots of Figure 7, further validates DiffCL’s robustness and scalability to high-diversity domains with considerable intra-class variance.</p> 
 <h2 data-bbox="556 951 691 972">F. Ablation Studies</h2> 
 <p data-bbox="555 975 1012 1135">To assess the contribution of each component in DiffCL, we conduct ablation experiments on all four datasets. The results are presented in Table X. Activating only the Cross-Centroid Asymmetric Reconstruction (CCAR) module improves accuracy by $1.9 \%$, while the Mutual Sample Inversion (MSI) module provides a $2.1 \%$ gain. The Adaptive Weighted Contrastive Loss (AWCL) contributes an additional $1.7 \%$ improvement. Combining all modules yields the best overall performance in classification and calibration.</p> 
 <ol data-bbox="555 1135 1006 1156"><li data-bbox="555 1135 1006 1156">The Effectiveness of the CCAR for Semantically-Aware</li></ol> 
 <p data-bbox="555 1153 1012 1352">Hard Sample Initialization: We compare confusion and error matrices generated with and without CCAR to evaluate the contribution. As illustrated in Fig. 8, the removal of CCAR leads to significantly higher confusion rates among semantically adjacent classes. Specifically, the error matrix in Fig. 8(b) shows severe misclassifications across multiple class boundaries, which are visibly alleviated in Fig. 8(d) with CCAR enabled. This suggests that the CCAR module effectively regularizes embedding directions, enabling the model to better distinguish hard negative pairs. Furthermore, Fig. 8(e) quantifies the error rate per super-class.</p> 
</body></html>
```